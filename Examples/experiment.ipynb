{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "\n",
    "from Config.config_reader import *\n",
    "from DataReaders.ASVspoof2015 import ASVspoof2015\n",
    "from DataReaders.ChenAudiosetDataset import ChenAudiosetDataset\n",
    "from DataReaders.DCASE2017_SE import DCASE2017_SE\n",
    "from DataReaders.DCASE2017_SS import DCASE2017_SS\n",
    "from DataReaders.ExtractionMethod import MelSpectrogramExtractionMethod\n",
    "from DataReaders.FSDKaggle2018 import FSDKaggle2018\n",
    "from DataReaders.Ravdess import Ravdess\n",
    "from DataReaders.SpeechCommands import SpeechCommands\n",
    "from MultiTask.MultiTaskHardSharing import MultiTaskHardSharing\n",
    "from MultiTask.MultiTaskHardSharingConvolutional import MultiTaskHardSharingConvolutional\n",
    "from MultiTask.MultiTaskModelFactory import MultiTaskModelFactory\n",
    "from Tasks.TrainingSetCreator import ConcatTrainingSetCreator\n",
    "from Training.Training import Training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "drive = r\"E:/\"\n",
    "data_base = r'E:\\Thesis_Results\\Data_Readers'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def run_training(train, test=None, fold=0, m=0):\n",
    "    model = mtmf.create_model(MultiTaskHardSharing.__name__,\n",
    "                                  input_size=train.datasets[0].get_input(0).flatten().shape[0],\n",
    "                                  task_list=train.get_task_list()) if m==0 else \\\n",
    "            mtmf.create_model(MultiTaskHardSharingConvolutional.__name__,\n",
    "                              task_list=train.get_task_list())\n",
    "\n",
    "    results = Training.create_results(modelname=model.name,\n",
    "                                          task_list=train.get_task_list(),\n",
    "                                          fold=fold,\n",
    "                                          results_path=os.path.join(drive, 'Thesis_Results', 'Experiment'),\n",
    "                                          num_epochs=meta_params['num_epochs'])\n",
    "    Training.run_gradient_descent(model=model,\n",
    "                                      concat_dataset=train,\n",
    "                                      results=results,\n",
    "                                      test_dataset=test,\n",
    "                                      **meta_params)\n",
    "\n",
    "def run_five_fold(key_list, m=0):\n",
    "    print('Starts {}'.format(key_list))\n",
    "    for train, test, fold in csc.generate_training_splits(key_list):\n",
    "        run_training(train, test, fold, m)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "test loop\n",
      "--------------------------------------------------\n",
      "start asvspoof2015\n",
      "done asvspoof2015\n",
      "start DCASE2017 SS\n",
      "done DCASE2017 SS\n",
      "start DCASE2017 SE\n",
      "done DCASE2017 SE\n",
      "start FSDKaggle 2018\n",
      "done FSDKaggle 2018\n",
      "start ravdess\n",
      "Done loading Ravdess\n",
      "start Speech commands\n",
      "Done loading Speech Commands\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print('test loop')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "csc = ConcatTrainingSetCreator(random_state=123,\n",
    "                                   nr_runs=4,\n",
    "                                   index_mode=False,\n",
    "                                   recalculate=False)\n",
    "csc.add_data_reader(ASVspoof2015(object_path=os.path.join(data_base, 'ASVspoof2015_{}'),\n",
    "                                 data_path=os.path.join(drive,\n",
    "                                                        r\"Thesis_Datasets\\Automatic Speaker Verification Spoofing \"\n",
    "                                                        r\"and Countermeasures Challenge 2015\\DS_10283_853\"),\n",
    "                                 ))\n",
    "# csc.add_data_reader(ChenAudiosetDataset(object_path=os.path.join(data_base, 'ChenAudiosetDataset'),\n",
    "#                                         data_path=os.path.join(drive + r':\\Thesis_Datasets\\audioset_chen\\audioset_filtered'),\n",
    "#                                         ))\n",
    "csc.add_data_reader(DCASE2017_SS(object_path=os.path.join(data_base, 'DCASE2017_SS_{}'),\n",
    "                                     data_path=os.path.join(drive, r'Thesis_Datasets\\DCASE2017')))\n",
    "csc.add_data_reader(DCASE2017_SE(object_path=os.path.join(data_base, 'DCASE2017_SE_{}'),\n",
    "                                     data_path=os.path.join(drive, 'Thesis_Datasets\\\\DCASE2017'),\n",
    "                                     ))\n",
    "csc.add_data_reader(FSDKaggle2018(object_path=os.path.join(data_base, 'FSDKaggle2018_{}'),\n",
    "                                      data_path=os.path.join(drive,\n",
    "                                                             r'Thesis_Datasets\\FSDKaggle2018\\freesound-audio-tagging'),\n",
    "                                      ))\n",
    "csc.add_data_reader(Ravdess(object_path=os.path.join(data_base, 'Ravdess'),\n",
    "                                data_path=os.path.join(drive, r\"Thesis_Datasets\\Ravdess\"),\n",
    "                            mode=2\n",
    "                                ))\n",
    "csc.add_data_reader(SpeechCommands(object_path=os.path.join(data_base, 'SpeechCommands_{}'),\n",
    "                                       data_path=os.path.join(drive, r'Thesis_Datasets\\SpeechCommands'),\n",
    "                                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mtmf = MultiTaskModelFactory()\n",
    "mtmf.add_modelclass(MultiTaskHardSharingConvolutional)\n",
    "mtmf.add_static_model_parameters(MultiTaskHardSharingConvolutional.__name__,\n",
    "                                 hidden_size=64,\n",
    "                                 n_hidden=4,\n",
    "                                 input_channels=1)\n",
    "mtmf.add_modelclass(MultiTaskHardSharing)\n",
    "mtmf.add_static_model_parameters(MultiTaskHardSharing.__name__,\n",
    "                                 **{\"hidden_size\": 512, \"n_hidden\": 3})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "extraction_params = {\n",
    "        \"extraction_params\": {\n",
    "            \"n_fft\": 1024,\n",
    "            \"hop_length\": 256,\n",
    "            \"n_mels\": 128,\n",
    "            \"window\": \"hann\"\n",
    "        },\n",
    "    }\n",
    "csc.add_signal_preprocessing(preprocess_dict=dict(resample_to=32000, mono=True))\n",
    "csc.add_extraction_method(MelSpectrogramExtractionMethod(\n",
    "    **extraction_params))\n",
    "\n",
    "csc.add_transformation_call('prepare_fit')\n",
    "csc.add_transformation_call('prepare_inputs')\n",
    "csc.add_transformation_call('normalize_fit')\n",
    "csc.add_transformation_call('normalize_inputs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "meta_params = {\n",
    "        \"batch_size\": 16,\n",
    "        \"num_epochs\": 200,\n",
    "        \"learning_rate\": 0.001\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading\n",
      "reading\n",
      "reading\n",
      "reading\n",
      "reading\n",
      "calculating\n",
      "Done loading Speech Commands dataset\n"
     ]
    }
   ],
   "source": [
    "# Create validation set\n",
    "set, _, _ = next(csc.generate_training_splits())\n",
    "validation = set.disconnect_test()\n",
    "next(validation.generate_train_test_set(n_splits=5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_training(validation, validation.test_set)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_list = [list(csc.get_keys())[0]]\n",
    "run_five_fold(key_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mtmf.add_static_model_parameters(MultiTaskHardSharing.__name__,\n",
    "                                 **{\"hidden_size\": 512, \"n_hidden\": 4})\n",
    "key_list = [list(csc.get_keys())[0]]\n",
    "run_five_fold(key_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_list = [list(csc.get_keys())[2]]\n",
    "run_five_fold(key_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_list = [list(csc.get_keys())[3]]\n",
    "run_five_fold(key_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_list = [list(csc.get_keys())[4]]\n",
    "run_five_fold(key_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_list = [list(csc.get_keys())[5]]\n",
    "run_five_fold(key_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_list = [list(csc.get_keys())[6]]\n",
    "run_five_fold(key_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_list = [list(csc.get_keys())[7]]\n",
    "run_five_fold(key_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ex in range(2):\n",
    "\n",
    "        keys = list(csc.get_keys())\n",
    "        comb_iterator = itertools.chain(*map(lambda x: itertools.combinations(keys, x), range(0, 2)))\n",
    "\n",
    "        for combo in comb_iterator:\n",
    "            key_list = list(combo)\n",
    "            for train, test, fold in csc.generate_training_splits(key_list):\n",
    "                for i in range(2):\n",
    "                    model = mtmf.create_model(MultiTaskHardSharing.__name__,\n",
    "                                              input_size=train.datasets[0].get_input(0).flatten().shape[0],\n",
    "                                              task_list=train.get_task_list()) if i == 1 else mtmf.create_model(\n",
    "                        MultiTaskHardSharingConvolutional.__name__,\n",
    "                        task_list=train.get_task_list())\n",
    "\n",
    "                    print('Model Created')\n",
    "\n",
    "                    results = Training.create_results(modelname=model.name,\n",
    "                                                      task_list=train.get_task_list(),\n",
    "                                                      fold=fold,\n",
    "                                                      results_path=drive + r\":\\Thesis_Results\",\n",
    "                                                      num_epochs=meta_params['num_epochs'])\n",
    "\n",
    "                    Training.run_gradient_descent(model=model,\n",
    "                                                  concat_dataset=train,\n",
    "                                                  results=results,\n",
    "                                                  batch_size=meta_params['batch_size'],\n",
    "                                                  num_epochs=meta_params['num_epochs'],\n",
    "                                                  learning_rate=meta_params['learning_rate'],\n",
    "                                                  test_dataset=test)\n",
    "\n",
    "\n",
    "# tensorboard --logdir F:\\Thesis_Results\\Training_Results\\experiments\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csc.add_extraction_method(MFCCExtractionMethod(**extraction_params))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}