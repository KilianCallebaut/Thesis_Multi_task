{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrKC1\\PycharmProjects\\Thesis\\Tests\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from torch import nn, Tensor\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from DataReaders.ChenAudiosetDataset import ChenAudiosetDataset\n",
    "from DataReaders.Test_fgo import Test_fgo\n",
    "from MultiTask.HardSharing import HardSharing\n",
    "from MultiTask.pytorch_multitask_example.multi_output_model import multi_output_model\n",
    "from Tasks.ConcatTaskDataset import ConcatTaskDataset\n",
    "from Tasks.Task import Task\n",
    "from Tasks.TaskDataset import TaskDataset\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "plt.ion()  # interactive mode\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# own model\n",
    "# Important: the tasks in task_list has to be the same as the order in concatTaskDataset\n",
    "# Required:\n",
    "# ConcatTaskDataset\n",
    "# ->    list of TaskDataset\n",
    "# ->    inputs: list of size nr_instances, flatened tensors\n",
    "# ->    targets: tensors of right outputs\n",
    "# ->    name: name as task, consistent with task_list\n",
    "# X_input_size: input nodes amount\n",
    "# task_list: list of object Task:\n",
    "# ->    name: name as task, consistent with concattaskdataset\n",
    "# ->    output_labels: list of string with output labels\n",
    "\n",
    "# test_fgo = Test_fgo()\n",
    "# training_dataset = test_fgo.toTaskDataset()\n",
    "#\n",
    "# model = HardSharing(test_fgo.get_input_nodes(), 128, 3, training_dataset.get_task_list())\n",
    "# model = model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "# multitask_example model\n",
    "# X_loaded = [Image.open('Datasets/images/' + x) for x in X_train]\n",
    "# X_loaded = [x.convert('RGB') for x in X_loaded]\n",
    "# X_loaded = [data_transforms['train'](x) for x in X_loaded]\n",
    "# X_input_size = X_loaded[0].shape[0]\n",
    "#\n",
    "# training_dataset = ConcatTaskDataset(\n",
    "#     [TaskDataset(inputs=X_loaded, targets=gender_train, name='gender'),\n",
    "#      TaskDataset(inputs=X_loaded, targets=region_train, name='region'),\n",
    "#      TaskDataset(inputs=X_loaded, targets=fighting_style_train, name='fighting'),\n",
    "#      TaskDataset(inputs=X_loaded, targets=alignment_train, name='alignment'),\n",
    "#      TaskDataset(inputs=X_loaded, targets=color_train, name='colors')]\n",
    "# )\n",
    "#\n",
    "# dd = .1\n",
    "# model_ft = models.resnet50(pretrained=True)\n",
    "# print(model_ft)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, 512)\n",
    "# model = multi_output_model(model_ft, dd, [gender_nodes, region_nodes, fighting_nodes, alignment_nodes, color_nodes])\n",
    "# model = model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chendata = ChenAudiosetDataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "chenTaskDataset = chendata.toTaskDataset()\n",
    "training_dataset = ConcatTaskDataset([chenTaskDataset])\n",
    "task_list = training_dataset.get_task_list()\n",
    "\n",
    "model = HardSharing(len(chenTaskDataset.inputs[0]), 128, 3, task_list)\n",
    "model = model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "Epoch 0\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 1\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 2\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 3\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 4\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 5\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 6\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 7\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 8\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 9\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 10\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 11\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 12\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 13\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 14\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 15\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 16\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 17\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 18\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 19\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 20\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 21\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 22\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 23\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 24\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 25\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 26\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 27\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 28\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 29\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 30\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 31\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 32\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 33\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 34\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 35\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 36\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 37\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 38\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 39\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 40\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 41\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 42\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 43\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 44\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 45\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 46\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 47\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 48\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n",
      "Epoch 49\n",
      "===========================================================\n",
      "Not updated parameters?\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": "HardSharing(\n  (model): Sequential(\n    (hard_sharing): FFNN(\n      (hidden): ModuleList(\n        (0): Linear(in_features=182, out_features=128, bias=True)\n        (1): Linear(in_features=128, out_features=128, bias=True)\n        (2): Linear(in_features=128, out_features=128, bias=True)\n        (3): Linear(in_features=128, out_features=128, bias=True)\n      )\n      (relu): ReLU()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (task_specific): TaskDependentLayers(\n      (task_nets): ModuleList(\n        (0): Linear(in_features=128, out_features=25, bias=True)\n      )\n    )\n  )\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Training.Training import Training\n",
    "print('started')\n",
    "Training.run_gradient_descent(\n",
    "    model=model,\n",
    "    concat_dataset=training_dataset,\n",
    "    batch_size=16,\n",
    "    num_epochs=50\n",
    "    # learning_rate=,\n",
    "    # weight_decay=,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_dataset,\n",
    "            # sampler=BalancedBatchSchedulerSampler(dataset=concat_dataset,\n",
    "            #                                       batch_size=batch_size),\n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            num_workers=0)\n",
    "\n",
    "model.eval()\n",
    "outputs = []\n",
    "trues = []\n",
    "for inputs, targets, names in train_loader:\n",
    "    out = model(inputs.cuda())\n",
    "    outputs.append(out)\n",
    "    true = targets\n",
    "    trues.append(true)\n",
    "outputs = torch.cat(outputs, dim=0).detach().cpu()\n",
    "trues = torch.cat(trues, dim=0).detach().cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 1967\n",
      "Total classified as positive: 2695\n",
      "Total positive cases: 9356.0\n",
      "Precision: 0.7298701405525208\n",
      "Recall: 0.210239418554938\n",
      "F1 Score: 0.32644593916491194\n",
      "\n",
      "Label: Typing\n",
      "True positives for 0: 2\n",
      "Total classified as positive for 0: 2\n",
      "Total positive cases for 0: 308.0\n",
      "Precision for 0: 1.0\n",
      "Recall for 0: 0.006493506493506494\n",
      "\n",
      "Label: Pink noise\n",
      "True positives for 1: 101\n",
      "Total classified as positive for 1: 167\n",
      "Total positive cases for 1: 315.0\n",
      "Precision for 1: 0.6047903895378113\n",
      "Recall for 1: 0.32063492063492066\n",
      "\n",
      "Label: Throat clearing\n",
      "True positives for 2: 0\n",
      "Total classified as positive for 2: 0\n",
      "Total positive cases for 2: 167.0\n",
      "Precision for 2: nan\n",
      "Recall for 2: 0.0\n",
      "\n",
      "Label: Hubbub, speech noise, speech babble\n",
      "True positives for 3: 0\n",
      "Total classified as positive for 3: 0\n",
      "Total positive cases for 3: 225.0\n",
      "Precision for 3: nan\n",
      "Recall for 3: 0.0\n",
      "\n",
      "Label: Speech\n",
      "True positives for 4: 0\n",
      "Total classified as positive for 4: 0\n",
      "Total positive cases for 4: 500.0\n",
      "Precision for 4: nan\n",
      "Recall for 4: 0.0\n",
      "\n",
      "Label: Inside, large room or hall\n",
      "True positives for 5: 0\n",
      "Total classified as positive for 5: 0\n",
      "Total positive cases for 5: 627.0\n",
      "Precision for 5: nan\n",
      "Recall for 5: 0.0\n",
      "\n",
      "Label: None of the above\n",
      "True positives for 6: 0\n",
      "Total classified as positive for 6: 0\n",
      "Total positive cases for 6: 500.0\n",
      "Precision for 6: nan\n",
      "Recall for 6: 0.0\n",
      "\n",
      "Label: Inside, small room\n",
      "True positives for 7: 368\n",
      "Total classified as positive for 7: 594\n",
      "Total positive cases for 7: 1642.0\n",
      "Precision for 7: 0.619528591632843\n",
      "Recall for 7: 0.2241169305724726\n",
      "\n",
      "Label: Male speech, man speaking\n",
      "True positives for 8: 0\n",
      "Total classified as positive for 8: 0\n",
      "Total positive cases for 8: 120.0\n",
      "Precision for 8: nan\n",
      "Recall for 8: 0.0\n",
      "\n",
      "Label: Chatter\n",
      "True positives for 9: 0\n",
      "Total classified as positive for 9: 0\n",
      "Total positive cases for 9: 162.0\n",
      "Precision for 9: nan\n",
      "Recall for 9: 0.0\n",
      "\n",
      "Label: Knock\n",
      "True positives for 10: 15\n",
      "Total classified as positive for 10: 18\n",
      "Total positive cases for 10: 179.0\n",
      "Precision for 10: 0.8333333134651184\n",
      "Recall for 10: 0.08379888268156424\n",
      "\n",
      "Label: Laughter\n",
      "True positives for 11: 214\n",
      "Total classified as positive for 11: 306\n",
      "Total positive cases for 11: 539.0\n",
      "Precision for 11: 0.6993464231491089\n",
      "Recall for 11: 0.3970315398886827\n",
      "\n",
      "Label: Clapping\n",
      "True positives for 12: 0\n",
      "Total classified as positive for 12: 0\n",
      "Total positive cases for 12: 239.0\n",
      "Precision for 12: nan\n",
      "Recall for 12: 0.0\n",
      "\n",
      "Label: Crowd\n",
      "True positives for 13: 536\n",
      "Total classified as positive for 13: 797\n",
      "Total positive cases for 13: 1229.0\n",
      "Precision for 13: 0.6725219488143921\n",
      "Recall for 13: 0.43612693246541906\n",
      "\n",
      "Label: Breathing\n",
      "True positives for 14: 0\n",
      "Total classified as positive for 14: 0\n",
      "Total positive cases for 14: 150.0\n",
      "Precision for 14: nan\n",
      "Recall for 14: 0.0\n",
      "\n",
      "Label: Door\n",
      "True positives for 15: 0\n",
      "Total classified as positive for 15: 0\n",
      "Total positive cases for 15: 114.0\n",
      "Precision for 15: nan\n",
      "Recall for 15: 0.0\n",
      "\n",
      "Label: Clicking\n",
      "True positives for 16: 0\n",
      "Total classified as positive for 16: 0\n",
      "Total positive cases for 16: 87.0\n",
      "Precision for 16: nan\n",
      "Recall for 16: 0.0\n",
      "\n",
      "Label: Female speech, woman speaking\n",
      "True positives for 17: 0\n",
      "Total classified as positive for 17: 0\n",
      "Total positive cases for 17: 137.0\n",
      "Precision for 17: nan\n",
      "Recall for 17: 0.0\n",
      "\n",
      "Label: Conversation\n",
      "True positives for 18: 0\n",
      "Total classified as positive for 18: 0\n",
      "Total positive cases for 18: 120.0\n",
      "Precision for 18: nan\n",
      "Recall for 18: 0.0\n",
      "\n",
      "Label: Silence\n",
      "True positives for 19: 488\n",
      "Total classified as positive for 19: 504\n",
      "Total positive cases for 19: 573.0\n",
      "Precision for 19: 0.9682539701461792\n",
      "Recall for 19: 0.8516579406631762\n",
      "\n",
      "Label: White noise\n",
      "True positives for 20: 29\n",
      "Total classified as positive for 20: 31\n",
      "Total positive cases for 20: 348.0\n",
      "Precision for 20: 0.9354838728904724\n",
      "Recall for 20: 0.08333333333333333\n",
      "\n",
      "Label: Applause\n",
      "True positives for 21: 214\n",
      "Total classified as positive for 21: 276\n",
      "Total positive cases for 21: 358.0\n",
      "Precision for 21: 0.7753623127937317\n",
      "Recall for 21: 0.5977653631284916\n",
      "\n",
      "Label: Cough\n",
      "True positives for 22: 0\n",
      "Total classified as positive for 22: 0\n",
      "Total positive cases for 22: 257.0\n",
      "Precision for 22: nan\n",
      "Recall for 22: 0.0\n",
      "\n",
      "Label: Television\n",
      "True positives for 23: 0\n",
      "Total classified as positive for 23: 0\n",
      "Total positive cases for 23: 239.0\n",
      "Precision for 23: nan\n",
      "Recall for 23: 0.0\n",
      "\n",
      "Label: Walk, footsteps\n",
      "True positives for 24: 0\n",
      "Total classified as positive for 24: 0\n",
      "Total positive cases for 24: 221.0\n",
      "Precision for 24: nan\n",
      "Recall for 24: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fntp = trues.sum()\n",
    "tpfp = (outputs >= 0.5).sum()\n",
    "tp = ((outputs[trues > 0.5] >= 0.5) == trues[trues > 0.5]).sum()\n",
    "precision = tp/tpfp\n",
    "recall = tp/fntp\n",
    "print('True positives: {}'.format(tp))\n",
    "print('Total classified as positive: {}'.format(tpfp))\n",
    "print('Total positive cases: {}'.format(fntp))\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1 Score: {}'.format(2*(precision*recall)/(precision+recall)))\n",
    "print()\n",
    "\n",
    "for i in range(trues.shape[1]):\n",
    "    trues_y = trues[:, i]\n",
    "    outputs_y = outputs[:, i]\n",
    "    fntp = trues_y.sum()\n",
    "    tpfp = (outputs_y >= 0.5).sum()\n",
    "    tp = ((outputs_y[trues_y > 0.5] >= 0.5) == trues_y[trues_y > 0.5]).sum()\n",
    "    print('Label: '+ chenTaskDataset.task.output_labels[i])\n",
    "    print('True positives for {}: {}'.format(i, tp))\n",
    "    print('Total classified as positive for {}: {}'.format(i, tpfp))\n",
    "    print('Total positive cases for {}: {}'.format(i, fntp))\n",
    "    print('Precision for {}: {}'.format(i, tp/tpfp))\n",
    "    print('Recall for {}: {}'.format(i, tp/fntp))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0113e-03, 3.6083e-03, 4.1867e-02, 4.5969e-03, 9.9742e-02, 1.4168e-02,\n",
      "         2.2154e-02, 1.6895e-01, 1.9300e-02, 9.4136e-03, 2.5174e-03, 2.7254e-01,\n",
      "         9.0539e-02, 5.3343e-02, 8.4156e-03, 6.5776e-03, 7.2212e-05, 3.6127e-02,\n",
      "         1.7849e-02, 8.7957e-05, 2.1319e-03, 5.0696e-03, 3.3034e-02, 1.0107e-02,\n",
      "         7.3191e-03],\n",
      "        [1.3281e-02, 5.3271e-02, 2.3084e-02, 3.9226e-02, 2.0886e-01, 1.7018e-01,\n",
      "         1.0834e-01, 2.8347e-01, 6.7080e-02, 1.7305e-02, 1.8015e-02, 3.4521e-02,\n",
      "         3.2050e-02, 5.1727e-02, 2.6902e-02, 2.9529e-02, 2.9227e-03, 8.6651e-02,\n",
      "         3.0438e-02, 4.3660e-03, 6.8486e-02, 1.2346e-02, 1.7688e-02, 7.9590e-02,\n",
      "         5.0720e-02]], device='cuda:0', grad_fn=<CatBackward>)\n",
      "tensor([[ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "inp = torch.stack([chenTaskDataset.inputs[0], chenTaskDataset.inputs[1]]).cuda()\n",
    "tgt = torch.stack([chenTaskDataset.__getitem__(0)[1], chenTaskDataset.__getitem__(1)[1]]).cuda()\n",
    "out = model(inp)\n",
    "\n",
    "print(out)\n",
    "print((out >= 0.5) == tgt)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}