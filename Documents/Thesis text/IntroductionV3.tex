\chapter{Introduction}

Multi-task learning (MTL) is a machine learning paradigm where multiple different tasks are learned at the same time, exploiting underlying task relationships, to arrive at a shared representation. While the principle goal was to improve generalization accuracy of a machine learning system \citep{caruana1997multitask}, over the years multitask learning has found other uses, including speed of learning, improved intelligibility of learned models \citep{caruana1997multitask}, classification fairness \citep{oneto2019taking} and as a means to compress multiple parallel models \citep{georgiev2017heterogeneous}. This led to the paradigm finding its usage in multiple fields, including audio recognition.\\

The field of audio recognition is varied and ever expanding, due to a growing number of large public and non-publicly available datasets (e.g. AudioSet \citep{gemmeke2017audio}) each with their own variations like sources, lengths and subjects. The tasks in the field can roughly be divided into three categories: Speech recognition tasks, Environmental Sound recognition tasks and Music recognition tasks, along with tasks that combine multiple domains \citep{duan2014survey}. These domains inherently have a different structure from each other, which requires different processing and classification schemes. Speech for example, is inherently built up out of elementary phonemes that are internally dependent, the tasks linked to which have to deal with the exact differentiation and characterization of these, to varying degrees. Environmental sounds in contrast, do not have such substructures and cover a larger range of frequencies. Music then has its own stationary patterns like melody and rhythm \citep{boregowda2018environmental}. A general purpose audio classification system, dealing with real life audio, would have to deal with the presence of each of these types of audio though, regardless if its task is only in one of the domains.\\    

Usually, in order to achieve high performance, it is necessary to construct a focused detector, which targets a few classes per task. Only focusing on one set of targets with a fitting dataset however, ignores the wealth of information available in other task-specific datasets, as well as failing to leverage the fact that they might be calculating the same features, especially in the lower levels of the architecture \citep{tagliasacchi2020multi}. This does not only entail a possible waste of information (and thus performance) but also entails a waste of computational resources, as each task might not require its own dedicated model to achieve the same level of performance. Originally conventional methods like Gaussian Mixture Models (GMM) and State Vector Machines (SVM) were the main focus, but due to the impressive results in visual tasks deep learning architectures have seen a lot of attention.  The emergence of deep learning MTL set-ups is still fairly recent in audio recognition. While it has seen both successful \citep{tonami2019joint} applications and less successful \citep{sakti2016deep} when combining different tasks, very little is known about the exact circumstances when MTL works in audio recognition. In fact, this question has not been investigated often in MTL in general.\\ 

This thesis will aim to investigate the relationship of multiple audio tasks in a MTL set-up. Following previous work in investigating the MTL set-up in different tasks in the Natural Language Processing field \citep{alonso2016multitask} \citep{bingel2017identifying}, 
this work will focus on experimenting with different MTL set-ups, where the multi-task runs are compared to the single task runs, evaluating the differences in results. The tasks examined will be unrelated, each having their own dedicated dataset. The goal is to identify connections between tasks in single-task learning that predict results in MTL. 