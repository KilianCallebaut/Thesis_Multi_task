\chapter{Related Work}

\section{Audio Recognition}
TODO: Explain the field of audio classification, how it normally works, what kind of tasks there are and what kind of things are researched

\section{Multi-task Learning}
TODO: Explain the field of multi-task learning, where it came from, what the paradigm brought in improvements and what kind of things are researched
TODO: Explain multi task learning with unimportant auxiliary task for performance improvement

\section{Multi-task Deep Learning Audio Tasks}
TODO: Explain the merging of these fields and what (little) work has been done there so far. Also what it requires for more work to be done and what the current work lacks.

Audio recognition tasks have only recently seen the adoption of multi-task frameworks, but for a quickly expanding set of reasons. This section maps out the key applications where, why and how deep learning systems where created to address problems. Single task focused systems were the way to go as instinctively it made sense that the best performances would be obtained by focusing on improving solely on building a system addressing that problem. Two factors however changed this notion. For one, systems in real life contexts often have to perform multiple related tasks at once TODO: REFERENCE. For another, sharing information between related tasks have been shown to improve performances as it averages noise patterns and creates a more robust representation of the original data for the final classifier(s) TODO: REFERENCE. Here, it will be demonstrated how these factors influenced the recent evolution towards trying to build systems that optimise for multiple objectives at once.\\

TODO: create table of papers

Where it was used:
Multiple tasks that needed to be performed but were done without multi-task
prof-life log Ziaei 2013
Zhang et al 2019
Park 2020



\textbf{Non-Parallel Multiple Tasks.} What will be done first is demonstrate the context where multiple tasks need to be performed, but were not optimized at the same time in a multi-task setting. For painting a clearer picture of contexts where multiple tasks have to be learned for the same data, this work will first delve into the context where this has been addressed without a multi-task framework. In TODO:REFERENCE, a lifelogging system is designed which tries to annotate the naturalistic audio from a sensor device with different types of labels to create a contextual summary of a person's day. This takes an audio stream and performs speech activity detection, the results of which then in turn uses for its other tasks. It estimates the amount of speakers in an audio segment; uses that estimate to then recognize the speakers and determine the primary and secondary speakers. At the same time it also performs the task of "environmental sniffing" or detecting the current environment of the device. The results of this set-up are illustrated in TODO: GET DIAGRAM. This example is given to illustrate the need and the types of tasks that would be learned at the same time in a context. Task information is shared here, but segmentally in stead of parallel. The thing is however that this does not share information to improve the representation, which ignores potentially useful information. This also requires every task to be performed individually, a set-up which might not always be allowed in terms of time and resource constraints.\\

To clarify how this singular focus forms the basis for problems in naturalistic audio contexts, the work done by \cite{park2020augmenting} is addressed. Here, the context of an audio device is being detected in a short time frame of seconds, by recognizing events that are tied together in wat they call contexts. First of all is the obvious need in this case for fast detection. Second point lies in their results. They find that including the detection of speech events significantly reduces the performance of the general classifier's performance. Speech audio is different in structure from other background audio events and likely requires its own model for reliable detection.\\

With the first example being one of tasks connected segmentially and the second being unified in the same classifier, the stage is set for exploring the compromise between the two: separated, yet parallel task inference. While Multi-Task settings had demonstrated their use in visual tasks TODO: REFERENCE, the adoption in audio tasks was (similar to the trajectory of deep learning algorithms) a bit slower to develop. The first domain that showed its potential were speech recognition tasks.\\


\textbf{Multi-Task Speech Recognition Tasks.} For Automatic Speech Recognition, multi-task learning has been around for a while. These tasks accept windows of audio features as input and return posterior probability distributions over phonetic targets \citep{meyer2019multi}. The targets can range from whole words to phonetic parts and even simply characters. The multi-task model itself either serves as an end-to-end recognition model or performs a modeling function in a hybrid model. \\

\cite{lu2004multitask} proposed an architecture where noisy speech audio is fed into a Recurrent Neural Network that has a number of shared layers with three output heads. One for the prediction of words, one for enhancing speech and one for gender detection. With adding these auxiliary tasks on the same dataset, they succesfully managed to improve the original task's - Speech recognition - performance. Their reasoning for utilising multi-task learning was that performance degrades dramatically for when there is a mismatch between train and testing conditions. Multi-Task learning added robustness to classification performance. \\

A lot of the work done in multi-task speech recognition focuses on this sort of improvement of the original signal's representation through adding additional optimization goals. \cite{seltzer2013multi} focus on the improvement of phoneme recognition by adding the prediction of the phone labels, state contexts and phone contexts - context here being predicting the label in the previous and next time frame. 
%TODO: FIND MORE EXAMPLES\\


Shift towards Multi-Task as performance improver

- Same dataset auxiliary
Kim et al. 2017
lee 2019
abrol 2020
Deshmukh 2020
zeng et al 2019
Fernando 2020

\textbf{General purpose audio}

The techniques that were found for Speech Recognition purposes eventually found their way for general purpose audio tasks. There are a few trends within acoustic multi-task definitions that will be discussed here, which will be important bases for the system to cover.  The trends deal with how the additional task was utilised in the same model. Four of these trends are addressed in this section: Auxiliary tasks on the same dataset, combining tasks from different datasets, splitting a task and finally multi-task learning for non-performance related issues. \\

\textbf{Auxiliary tasks on the same dataset.} The first strain of set-ups concern audio tasks that receive an additional task on the same dataset. This is usually with the aim to improve the original task's performance. These in turn come in two forms: supervised tasks \citep{kim2017speech} \citep{zeng2019spectrogram} \citep{abrol2020learning} \citep{fernando2020temporarily} \citep{wu2020domain} \citep{sun2017compressed} \citep{lopez2019keyword} \citep{panchapagesan2016multi} and self-supervised tasks \citep{lee2019label}  \citep{deshmukh2020multi} \citep{lu2004multitask}.  \\

Often, the auxiliary task is not important and only serves to help the neural network create a representation of the data that is formed for its qualities the additional tasks require. With a supervised task as an auxiliary task, this takes a more semantic form. The task is semantically related. In \cite{zeng2019spectrogram}, the multi-task set-up results are explored for combining speaker identification and accent recognition in one case and emotion recognition in speech and emotion recognition in song in another. In both these instances, the semantic connections for the targets are clear.  \cite{abrol2020learning} does this concept slightly different and learns basically the same task but at different abstraction levels, in order to improve learn leveraging hierarchical relation structures. The set-up for \cite{fernando2020temporarily} contains detecting speech activity along with predicting the next audio segment, using layers of LSTM. Here layers  are shared at different levels, with a generative adversarial network that learns the loss function.\\


For the other scenario where the set-up adds a self-supervised task, this usually comes in the form of transforming the input signal according to different qualities, which will be transferred to the task at hand. \cite{lee2019label} investigates the effect of adding next-step prediction, noise reduction and upsampling of an audio signal as an auxiliary task to audio tagging, speaker identification and keyword detection tasks. Each possible subgroup of auxiliary tasks are tried.  With this it successfully tries to get more efficiency out of its labelled data. \cite{deshmukh2020multi} recreates the Time Frequency representation of audio as its auxiliary task to event detection. This aims to reduce the noise of the internal representation used for classification which makes it function better as a classifier based on noisy recordings (like in real life contexts). It also utilises Multiple Instance Learning, which is a learning mechanism where instances get put into positive and negative bags.  Positive bags do not only contain instances that are positive for that label - at least one for sure -, but negative bags do. \cite{lu2004multitask}, which has been discussed before, is a hybrid of these two forms. One of its auxiliary task is gender detection (first scenario) and the other is speech enhancement (second scenario). \\

For the system to be created this signifies a lot of different possibilities in terms of possible targets, beyond simple labels as well as a possibly inexhaustible range for models and training requirements. Any abstraction made in this regard must be fully adaptable. Tasks should also freely be addable or retractable in order to investigate its combinations to the main task. Furthermore, grouping instances should be possible, as seen in the example for Multiple Instance Learning. \\

- Other dataset other task
Sakti et al 2016
Tonami 2019
xu 2019
Huang 2020
Imoto
Jung et al 2020
komatsu 2020


- Same Task split in two
Morfi 2018
Pankajakshan
Phan et al 2019
\citep{phan2017dnn}
Xia 2020
\citep{nwe2017convolutional}


Multi-Task Learning for other purposes
Georgiev
Tagliasacchi




\section{Development Frameworks}
TODO: Get examples in from other development frameworks, how they answered the needs in their fields and why they are needed
