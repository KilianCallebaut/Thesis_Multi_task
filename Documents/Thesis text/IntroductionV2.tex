\chapter{Introduction}

Multi-task learning (MTL) is a machine learning paradigm where multiple different tasks are learned at the same time, exploiting underlying task relationships, to arrive at a shared representation. While the principle goal was to improve generalization accuracy of a machine learning system \citep{caruana1997multitask}, over the years multitask learning has found other uses, including speed of learning, improved intelligibility of learned models \citep{caruana1997multitask}, classification fairness \citep{oneto2019taking} and as a means to compress multiple parallel models \citep{georgiev2017heterogeneous}. This led to the paradigm finding its usage in multiple fields, including audio recognition.\\

The field of audio recognition is varied and ever expanding, due to a growing number of large public and non-publicly available datasets (e.g. AudioSet \citep{gemmeke2017audio}) each with their own variations like sources, lengths and subjects. The tasks in the field can roughly be divided into three categories: Speech recognition tasks, Environmental Sound recognition tasks and Music recognition tasks, along with tasks that combine multiple domains \citep{duan2014survey}. These domains inherently have a different structure from each other, which requires different processing and classification schemes. Speech for example, is inherently built up out of elementary phonemes that are internally dependent, the tasks linked to which have to deal with the exact differentiation and characterization of these, to varying degrees. Environmental sounds in contrast, do not have such substructures and cover a larger range of frequencies. Music then has its own stationary patterns like melody and rhythm \citep{boregowda2018environmental}. A general purpose audio classification system, dealing with real life audio, would have to deal with the presence of each of these types of audio though, regardless if its task is only in one of the domains.\\    

Usually, in order to achieve high performance, it is necessary to construct a focused detector, which targets a few classes per task. Only focusing on one set of targets with a fitting dataset however, ignores the wealth of information available in other task-specific datasets, as well as failing to leverage the fact that they might be calculating the same features, especially in the lower levels of the architecture \citep{tagliasacchi2020multi}. This does not only entail a possible waste of information (and thus performance) but also entails a waste of computational resources, as each task might not require its own dedicated model to achieve the same level of performance. Originally conventional methods like Gaussian Mixture Models (GMM) and State Vector Machines (SVM) were the main focus, but due to the impressive results in visual tasks deep learning architectures have seen a lot of attention.  The emergence of deep learning MTL set-ups is still fairly recent in audio recognition. While it has seen both successful \citep{tonami2019joint} applications and less successful \citep{sakti2016deep} when combining different tasks, very little is known about the exact circumstances when MTL works in audio recognition. In fact, this question has not been investigated often in MTL in general.\\ 

This thesis will aim to investigate the relationship of multiple audio tasks in a MTL set-up. Following previous work in investigating the MTL set-up in different tasks in the Natural Language Processing field \citep{alonso2016multitask} \citep{bingel2017identifying}, 
this work will focus on experimenting with different MTL set-ups, where the multi-task runs are compared to the single task runs, evaluating the differences in results. The tasks examined will be unrelated, each having their own dedicated dataset. The goal is to identify connections between tasks in single-task learning that predict results in MTL. 

The rest of this chapter will define the exact problem this work is addressing, then address this in specific research questions, declare the contributions of this project and finally outline the rest of the document. 

\section{Problem Statement}

Tasks with dedicated datasets bring together

\begin{itemize}
	\item Little research about when multi-task works
	\item power in audio comes from being able to harness the power multiple dedicated datasets
	\item Multiple different tasks in 1 classifier
	\item Question is both which/how many can you combine while maintaining predictive power and what their effect is on each other for further performance development
	\item Do these effects remain when switching classifier
\end{itemize}

While most audio classifier research focuses on building systems optimized on dedicated datasets, general purpose classification needs require multiple tasks to be performed at once. While it is possible to build a separate classifier per task, trained on their dedicated dataset, this entails that a lot of work is done in parallel, which perhaps should not be. Not only does this waste computational resources (which is important for on-device inference), but also ignores to leverage potential useful information in other tasks. Building a multi-head model with shared embedding layers addresses this problem, as the low-level features are learned simultaneous saving space and time as well as sharing information coming from every annotated training set. While this has seen some application \citep{tagliasacchi2020multi}, \citep{georgiev2017heterogeneous}, \citep{lee2019label} proving the viability of this approach in audio, no in depth look has been taken in regards to the effects of this combinatory approach. The main questions that remain unanswered are when this works and what the effects of the joint learning set-up in audio classification are, beyond general performance evaluation.

\section{Research Questions}

In this thesis different combinations of tasks are evaluated in a MTL setup. The example of \citep{bingel2017identifying} is followed in that this work will try to identify data characteristics and patterns both in single-task and dual-task learning that predict task interactions in MTL deep neural networks. 

\begin{table}[ht]
	\caption{Research questions} % title of Table
	\centering % used for centering table
	\begin{tabular}{p{\textwidth}} % centered columns (4 columns)
		\hline\hline %inserts double horizontal lines
		Question \\ [0.5ex] % inserts table
		%heading
		\hline % inserts single horizontal line
		When do Acoustic Classification tasks learned in a deep learning multi-task hard parameter sharing set-up improve each other? \\ % inserting body of the table
		
		\hline\hline %inserts double horizontal lines
		Subquestions \\ [0.5ex] % inserts table
		%heading
		\hline
		Which unrelated Acoustic Classification tasks, learned in a deep learning multi-task, hard parameter sharing set-up, improve each other? \\
		\hline % inserts single horizontal line
		What measurements can predict success in the multi-task set-up? \\
		
		\hline
		Do the task relationships demonstrate similarities when changing the classifier?\\
		
		\hline
		Are the task combination effects consistent when combining further?
				
		\\ [1ex] % [1ex] adds vertical space
		\hline %inserts single line
	\end{tabular}
	\label{table:questions} % is used to refer this table in the text
\end{table}

\section{Contributions}

\section{Outline}